# Repo Chatbot

A Dockerized chatbot app that reads documents and embeddings from a GitHub repo (indexed by Obsidian Copilot) and answers questions.

## Features

- Reads embeddings generated by Obsidian Copilot (`.copilot-index`).
- Supports OpenAI, Azure OpenAI, and Anthropic API providers.
- Streamlit-based Chat UI.
- **Environment-based configuration**: Pre-configure AI models via `docker-compose.yml` to hide the setup UI.
- **Git integration**: Clone and update source repositories directly from the UI.
- **Index management**: Reload embeddings without restarting the container.

## Usage

### Quick Start

1. **Prepare your Data**: Ensure your repository has a `.copilot-index` folder with embeddings.

2. **Configure `docker-compose.yml`**: Edit the environment variables (see [Configuration](#configuration) below).

3. **Run with Docker**:

   ```bash
   docker-compose up --build
   ```

4. **Access the App**: Open [http://localhost:8501](http://localhost:8501).

### Manual Docker Run

```bash
docker run -p 8501:8501 -v /path/to/your/repo:/data -e REPO_PATH=/data repo-chatbot
```

## Configuration

All configuration is done via environment variables in `docker-compose.yml`.

### AI Model Configuration

When these variables are set, the model setup sidebar is hidden and the app uses these pre-configured values:

```yaml
environment:
  # Chat Model Settings
  - CHAT_PROVIDER=OpenAI              # Options: OpenAI, Azure OpenAI, Anthropic, Mock
  - CHAT_API_KEY=your-api-key
  - CHAT_MODEL=gpt-3.5-turbo          # Model name or Azure deployment name
  
  # Azure-specific Chat Settings (only needed for Azure OpenAI)
  - CHAT_AZURE_ENDPOINT=https://your-resource.openai.azure.com/
  - CHAT_API_VERSION=2023-05-15
  
  # Embedding Model Settings
  - EMBEDDING_PROVIDER=OpenAI         # Options: OpenAI, Azure OpenAI, Mock
  - EMBEDDING_API_KEY=                # Leave empty to use CHAT_API_KEY
  - EMBEDDING_MODEL=text-embedding-ada-002
  
  # Azure-specific Embedding Settings (only needed for Azure OpenAI)
  - EMBEDDING_AZURE_ENDPOINT=https://your-resource.openai.azure.com/
  - EMBEDDING_API_VERSION=2023-05-15
```

If `CHAT_PROVIDER` is not set, the app will show the full model configuration UI in the sidebar.

### Git Repository Configuration

Enable git integration to clone and update your data repository directly from the UI:

```yaml
environment:
  - GIT_REPO_URL=https://github.com/your-org/your-repo.git
  - GIT_ACCESS_TOKEN=ghp_xxxxxxxxxxxx  # Required for private repos
```

**Features:**
- If `/data` is not a git repository, a **Clone Repository** button appears to initialize it.
- If `/data` is already a git repository, an **Update Sources** button appears to pull the latest changes.
- Git LFS files are automatically downloaded during clone/pull operations.
- After updates, the embedding index is automatically reloaded.

**Creating a GitHub Personal Access Token:**
1. Go to GitHub → Settings → Developer settings → Personal access tokens → Tokens (classic)
2. Generate a new token with `repo` scope (for private repos)
3. Copy the token and add it to `GIT_ACCESS_TOKEN`

### Index Management

The sidebar includes an **Index Status** section with:
- Number of loaded chunks displayed
- **Reload Index** button to reload embeddings from disk without restarting

This is useful when embeddings are updated externally or after a git pull.

## Development

- `src/app.py`: Main application entry point (Streamlit).
- `src/loader.py`: Handles loading of embeddings.
- `src/chat.py`: Logic for similarity search and LLM interaction.
